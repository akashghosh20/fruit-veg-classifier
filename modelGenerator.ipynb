{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff51608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60955 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "base_dir = \"C:/Users/Administrator/Downloads/FruitsAndVegDetect-main/Fruit-Images-Dataset-master/Training\"\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range= 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.1,\n",
    "    fill_mode = 'nearest',\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(base_dir,target_size=(IMAGE_SIZE,IMAGE_SIZE),batch_size=BATCH_SIZE,subset='training')\n",
    "\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "with open('labels.txt','w') as f:\n",
    "    f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMG_SHAPE = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top = False,weights = 'imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Conv2D(32,3,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(131,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "epochs = 10\n",
    "model.fit(train_generator,epochs=epochs,steps_per_epoch=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to your SavedModel directory\n",
    "\n",
    "# Define the path where you want to save the .tflite file\n",
    "\n",
    "save_model_dir = \"E:\\\\Deep Learning Projects\\\\Model\\\\vegetables\"\n",
    "saved_model = tf.saved_model.load(model,save_model_dir)\n",
    "tflite_model_path = \"E:\\\\Deep Learning Projects\\\\Model\\\\vegModel\"\n",
    "\n",
    "# Load the SavedModel\n",
    "\n",
    "\n",
    "# Convert the SavedModel to a TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to the specified path\n",
    "with open('vegModels.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model saved as {tflite_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
